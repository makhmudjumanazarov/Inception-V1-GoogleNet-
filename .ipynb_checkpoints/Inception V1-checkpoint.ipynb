{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV1(GoogleNet) Architecture via Tensorflow\n",
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception Module\n",
    "\n",
    "\n",
    "Each Inception block consists of four parallel paths at which convolution layers with different kernel sizes are applied:\n",
    "\n",
    "- The first path uses a convolutional layer with a window size of 1 × 1.\n",
    "\n",
    "- In the second and the third paths, a convolutional layer of size 1 × 1 is used before applying two expensive 3 × 3 and 5 × 5 convolutions. The 1×1 convolution helps to reduce the number of filter channels, thus reducing the model complexity.\n",
    "\n",
    "- The fourth path uses a max-pooling layer to reduce the resolution of the input, and it is followed by a 1 × 1 convolutional layer to reduce the dimension.\n",
    "\n",
    "These four paths use appropriate padding so that the input and output have the same size. The concatenation of these four paths allows scanning the input in different resolutions. Especially, the model complexity is minimized thanks to the application of a 1 × 1 convolutional layer in each path.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images/Inception_module.jpg\" style=\"width:900px;height:450px;\" />\n",
    "    <br>\n",
    "    <caption><center> <u> <font color='purple'> <b>Figure 1</b> </u><font color='purple'><b></b></center></caption>\n",
    "</div>\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception Block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4):\n",
    "    # Input: \n",
    "    # - f1: number of filters of the 1x1 convolutional layer in the first path\n",
    "    # - f2_conv1, f2_conv3 are number of filters corresponding to the 1x1 and 3x3 convolutional layers in the second path\n",
    "    # - f3_conv1, f3_conv5 are the number of filters corresponding to the 1x1 and 5x5  convolutional layer in the third path\n",
    "    # - f4: number of filters of the 1x1 convolutional layer in the fourth path\n",
    "    \n",
    "    # first path:\n",
    "    path1 = Conv2D(filters = f1, kernel_size = (1, 1), padding = 'same', activation = 'relu')(input_layer)\n",
    "    \n",
    "    # second path:\n",
    "    path2 = Conv2D(filters = f2_conv1, kernel_size=(1, 1), padding = 'same', activation='relu')(input_layer)\n",
    "    path2 = Conv2D(filters = f2_conv3, kernel_size=(3, 3), padding = 'same', activation='relu')(path2)\n",
    "\n",
    "    # third path:\n",
    "    path3 = Conv2D(filters = f3_conv1, kernel_size=(1, 1), padding = 'same', activation='relu')(input_layer)\n",
    "    path3 = Conv2D(filters = f3_conv5, kernel_size=(5, 5), padding = 'same', activation='relu')(path3)\n",
    "    \n",
    "    # fourth path:\n",
    "    path4 = MaxPooling2D(pool_size=(3,3), strides = (1, 1), padding = 'same')(input_layer)\n",
    "    path4 = Conv2D(filters=f4, kernel_size=(1,1), activation = 'relu', padding = 'same')(path4)\n",
    "    \n",
    "    output_layer = concatenate([path1, path2, path3, path4], axis = -1)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNet\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"images/GoogLeNet_incarnation_of_the_Inception_Architecture.png\" style=\"width:900px;height:450px;\" />\n",
    "    <br>\n",
    "    <caption><center> <u> <font color='purple'> <b>Figure 2</b>:  </u><font color='purple'><b>GoogLeNet incarnation of the Inception Architecture</b></center></caption>\n",
    "</div>\n",
    "\n",
    "##### Steps:\n",
    "- The input size image is 224 × 224.\n",
    "- There are nine Inception blocks in this network.\n",
    "- There are four max-pooling layers outside the Inception blocks, in which two layers are located between blocks 3–4 and block 7–8. These max-pooling layers help to reduce the size of the input data, thus reduce the model complexity as well as the computational cost.\n",
    "- This network inherits the idea of using an average pooling layer from NiN, which helps to improve the model performance and reduce overfitting.\n",
    "- A dropout layer (with 40%) is utilized before the linear layer. This is also an efficient regularization method to reduce the overfitting phenomena. The output layer uses the softmax activation function to give 1000 outputs which are corresponding to the number of categories in the ImageNet dataset.\n",
    "        \n",
    "Besides, some extra networks are added on the side, which encourages discrimination in the lower stages in the classifier, increases the gradient signal that gets backpropagation, and provides additional regularization. The structure of these networks includes:\n",
    "        \n",
    "- An average pooling layer with pooling size 5 × 5 and stride 3.\n",
    "- A 1 × 1 convolutional layer with 128 filters for dimensional reduction and a rectified linear activation.\n",
    "- A fully connected layer with 1024 units and a rectified linear activation.\n",
    "- A dropout with a ratio of 70% of outputs.\n",
    "- An output layer that used a softmax activation function to classify the object into one of 1000 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoogLeNet(units1, units2):\n",
    "    \n",
    "    # Input Layer \n",
    "    input_layer = Input(shape = (224, 224, 3))\n",
    "    \n",
    "    # Convolution layer: filters = 64, kernel_size = (7, 7), strides = (2,2)\n",
    "    X = Conv2D(filters = 64, kernel_size=(7, 7), strides=(2, 2), padding='valid', activation='relu')(input_layer)\n",
    "    \n",
    "    # MaxPooling layer: pool_size = (3,3), strides = (2, 2)\n",
    "    X = MaxPooling2D(pool_size = (3, 3), strides = (2, 2))(X)\n",
    "    \n",
    "    # Convolution layer: filters = 64, kernel_size = (1, 1), strides = (1, 1)\n",
    "    X = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1), padding = 'same', activation='relu')(X)\n",
    "    \n",
    "    # Convolution layer: filters = 192, kernel_size = (3, 3)\n",
    "    X = Conv2D(filters = 192, kernel_size=(3, 3), padding='same', activation='relu')(X)\n",
    "    \n",
    "    # MaxPooling pool_size = (3,3), strides = (2,2)\n",
    "    X = MaxPooling2D(pool_size=(3,3), strides = (2,2))\n",
    "    \n",
    "    # First Inception Block\n",
    "    X = Inception_block(X, f1 = 64, f2_conv1=96, f2_conv3=128, f3_conv1=16, f3_conv5=32, f4=32)\n",
    "    \n",
    "    # Second Inception Block\n",
    "    X = Inception_block(X, f1 = 128, f2_conv1=128, f2_conv3=192, f3_conv1=32, f3_conv5=96, f4=64)\n",
    "    \n",
    "    # MaxPooling layer: pool_size = (3, 3), strides = (2, 2)\n",
    "    X = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(X)\n",
    "    \n",
    "    # Third Inception Block\n",
    "    X = Inception_block(X, f1 = 192, f2_conv1=96, f2_conv3=208, f3_conv1=16, f3_conv5=48, f4=64)\n",
    "    \n",
    "    # Extra Network 1:\n",
    "    X1 = AveragePooling2D(pool_size=(5, 5), strides=(3, 3))(X)\n",
    "    X1 = Conv2D(filters = 128, kernel_size = (1, 1), padding='same', activation='relu')(X1)\n",
    "    X1 = Flatten()(X1)\n",
    "    X1 = Dense(1024, activation = 'relu')(X1)\n",
    "    X1 = Dropout(0.7)(X1)\n",
    "    X1 = Dense(units1, activation = 'softmax')(X1)\n",
    "    \n",
    "    # Fourth Inception Block\n",
    "    X = Inception_block(X, f1 = 160, f2_conv1=112, f2_conv3=224, f3_conv1=24, f3_conv5=64, f4=64)\n",
    "    \n",
    "    # Fifth Inception Block \n",
    "    X = Inception_block(X, f1 = 128, f2_conv1=128, f2_conv3=256, f3_conv1=24, f3_conv5=64, f4 = 64)\n",
    "    \n",
    "    # Sixth Inception Block\n",
    "    X = Inception_block(X, f1 = 112, f2_conv1 = 144, f2_conv3 = 288, f3_conv1 = 32, f3_conv5 = 64, f4 = 64)\n",
    "    \n",
    "    # Extra Network 2:\n",
    "    X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "    X2 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X2)\n",
    "    X2 = Flatten()(X2)\n",
    "    X2 = Dense(1024, activation = 'relu')(X2)\n",
    "    X2 = Dropout(0.7)(X2)\n",
    "    X2 = Dense(1000, activation = 'softmax')(X2)\n",
    "    \n",
    "    # Seventh Inception Block\n",
    "    X = Inception_block(X, f1=256, f2_conv1=160, f2_conv3=320, f3_conv1=32, f3_conv5=128, f4=128)\n",
    "    \n",
    "    # MaxPooling layer: pool_size = (3, 3), strides = (2, 2)\n",
    "    X = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(X)\n",
    "    \n",
    "    # Eighth Inception Block\n",
    "    X = Inception_block(X, f1=256, f2_conv1=160, f2_conv3=320, f3_conv1=32, f3_conv5=128, f4=128)\n",
    "    \n",
    "    # Ninth Inception Block\n",
    "    X = Inception_block(X, f1=384, f2_conv1=192, f2_conv3=384, f3_conv1=48, f3_conv5=128, f4=128)\n",
    "    \n",
    "    # GlobalAveragePooling layer\n",
    "    X = GlobalAveragePooling2D((X)\n",
    "    \n",
    "    # Dropout layer\n",
    "    X = Dropout(0.4)(X)\n",
    "                               \n",
    "    # Output layer\n",
    "    X = Dense(units2, activation='softmax')(X)\n",
    "    \n",
    "    # Model\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
